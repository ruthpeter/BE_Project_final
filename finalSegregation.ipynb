{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalSegregation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthpeter/BE_Project_final/blob/master/finalSegregation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YGJgStv-dwsp",
        "colab_type": "code",
        "outputId": "f6025db2-888e-463a-8032-61e818991943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XOhMp0orgaAc",
        "colab_type": "code",
        "outputId": "9b3647d0-a93b-46fe-e485-6d48648d8994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.models import model_from_json\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VGacyOSFcvu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJZEKhXrPu_a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_img(location):\n",
        "  path = os.path.abspath('.cnn.py') #absolute path of program\n",
        "  path = re.sub('[a-zA-Z\\s._]+$', '', path) #remove unintended file \n",
        "  print(path)\n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  dirs = os.listdir(path+'drive/My Drive/UCMerced_LandUse/Images/')\n",
        "  print(dirs)\n",
        "  label = 0\n",
        "  for i in dirs:\n",
        "    n = 0\n",
        "    count = 0\n",
        "    for pic in glob.glob(path+'drive/My Drive/UCMerced_LandUse/Images/'+i+'/*.tif'):\n",
        "      im = Image.open(pic)\n",
        "      im = np.array(im)\n",
        "      if((im.shape[0]==256) and (im.shape[1] ==256) and count < 99): \n",
        "        r = im[:,:,0]\n",
        "        g = im[:,:,1]\n",
        "        b = im[:,:,2]\n",
        "        if(n<5): # 5 data in beginning set as test data\n",
        "          x_test.append([r,g,b])\n",
        "          y_test.append([label])\n",
        "        else: #remaining data set as training data\n",
        "          x_train.append([r,g,b])\n",
        "          y_train.append([label])\n",
        "        n = n + 1\n",
        "        count = count + 1\n",
        "    label = label + 1\n",
        "  return np.array(x_train),np.array(y_train),np.array(x_test),np.array(y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42m-DtZ5P1WV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_img(location):\n",
        "  path = os.path.abspath('.cnn.py') #absolute path of program\n",
        "  path = re.sub('[a-zA-Z\\s._]+$', '', path) #remove unintended file\n",
        "  x_test=[]\n",
        "  y_test=[]\n",
        "  im = Image.open(path+'e006.tiff')\n",
        "  im = np.array(im)\n",
        "  print(im.shape[0])\n",
        "  if((im.shape[0]==256) and (im.shape[1] ==256)): \n",
        "\t\t\tr = im[:,:,0]\n",
        "\t\t\tg = im[:,:,1]\n",
        "\t\t\tb = im[:,:,2]\n",
        "\t\t\tx_test.append([r,g,b])\n",
        "\t\t\ty_test.append(17)\n",
        "  return np.array(x_test),np.array(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QgJTN-iDP-gm",
        "colab_type": "code",
        "outputId": "0bf16d1e-229e-4f10-c5d5-c66118143f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "img_rows = 256\n",
        "img_cols = 256\n",
        "num_class = 21\n",
        "x_train,y_train,x_test,y_test = read_img('drive/My Drive/UCMerced_LandUse/Images/')\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
        "\n",
        "\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, 21)\n",
        "y_test = keras.utils.to_categorical(y_test, 21)\n",
        "\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "\n",
        "# #model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "# #model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# #model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "# #model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "\n",
        "# model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# #model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "# #model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "# model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# #model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "# #model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "# model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(Dense(21, activation='softmax'))\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu',input_shape=input_shape))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
        "\n",
        "\n",
        "#model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "#model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "#model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Dense(512))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "#model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(512))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.Dense(21))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "#model.summary()\n",
        "\n",
        "# model.compile(\n",
        "#       optimizer='adam',\n",
        "#       loss='categorical_crossentropy',\n",
        "#       metrics=['acc'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-49dfec23cf5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/UCMerced_LandUse/Images/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1d868f156214>\u001b[0m in \u001b[0;36mread_img\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'drive/My Drive/UCMerced_LandUse/Images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/*.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2319\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2CHbIWKozeDy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "U-net demo "
      ]
    },
    {
      "metadata": {
        "id": "VcEcDJpbPbHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation\n",
        "\n",
        "import cv2\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from keras.optimizers import Nadam\n",
        "import pandas as pd\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "import os\n",
        "\n",
        "from keras.models import model_from_json\n",
        "import datetime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-7VKQPAS_Wc",
        "colab_type": "code",
        "outputId": "7c5a68c5-45ea-469f-c448-e394223dae1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tifffile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tifffile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/23/b3ae663ef38961348c59b27281919cff1de2e0034088e90ff8f5931a578c/tifffile-2019.2.22-py2.py3-none-any.whl (127kB)\n",
            "\r\u001b[K    8% |██▋                             | 10kB 14.6MB/s eta 0:00:01\r\u001b[K    16% |█████▏                          | 20kB 3.1MB/s eta 0:00:01\r\u001b[K    24% |███████▊                        | 30kB 4.5MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 40kB 3.0MB/s eta 0:00:01\r\u001b[K    40% |████████████▉                   | 51kB 3.7MB/s eta 0:00:01\r\u001b[K    48% |███████████████▍                | 61kB 4.4MB/s eta 0:00:01\r\u001b[K    56% |██████████████████              | 71kB 5.0MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▌           | 81kB 5.6MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████         | 92kB 6.2MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▋      | 102kB 4.9MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 112kB 5.0MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▊ | 122kB 7.0MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 133kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from tifffile) (1.14.6)\n",
            "Installing collected packages: tifffile\n",
            "Successfully installed tifffile-2019.2.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XYbFodKNS7Zv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from shapely.wkt import loads as wkt_loads\n",
        "import tifffile as tiff\n",
        "import os\n",
        "import random\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout ,Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import jaccard_similarity_score\n",
        "from shapely.geometry import MultiPolygon, Polygon\n",
        "import shapely.wkt\n",
        "import shapely.affinity\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qy0txF9PeAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pixel_softmax(y_true, y_pred):\n",
        "   y_pred = K.reshape(y_pred, (-1, num_mask_channels))\n",
        "   y_true = K.reshape(y_true, (-1, num_mask_channels))\n",
        "   return K.mean(K.categorical_crossentropy(y_pred, y_true, from_logits=True))\n",
        "\n",
        "\n",
        "def ConvBN2(x, num_filter, stride_size=3):\n",
        "    x = Conv2D(num_filter, (stride_size, stride_size), padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('selu')(x)\n",
        "    x = Conv2D(num_filter, (stride_size, stride_size), padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('selu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKvTS7o9GqUV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input, merge, UpSampling2D, Cropping2D, ZeroPadding2D, Reshape, core, Convolution2D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34q4Q70-zdB6",
        "colab_type": "code",
        "outputId": "29aeeb4b-696c-44dd-c6e9-b0afd721caab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.keras import models\n",
        "from tensorflow.contrib.keras import layers \n",
        "\n",
        "img_rows = 256\n",
        "img_cols = 256\n",
        "num_class = 21\n",
        "x_train,y_train,x_test,y_test = read_img('drive/My Drive/UCMerced_LandUse/Images/')\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
        "\n",
        "\n",
        "input_shape = (img_rows, img_cols,3)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, 21)\n",
        "y_test = keras.utils.to_categorical(y_test, 21)\n",
        "\n",
        "\n",
        "class UNet():\n",
        "    def __init__(self):\n",
        "        print ('build UNet ...')\n",
        "\n",
        "    def get_crop_shape(self, target, refer):\n",
        "        # width, the 3rd dimension\n",
        "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
        "        assert (cw >= 0)\n",
        "        if cw % 2 != 0:\n",
        "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
        "        else:\n",
        "            cw1, cw2 = int(cw/2), int(cw/2)\n",
        "        # height, the 2nd dimension\n",
        "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
        "        assert (ch >= 0)\n",
        "        if ch % 2 != 0:\n",
        "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
        "        else:\n",
        "            ch1, ch2 = int(ch/2), int(ch/2)\n",
        "\n",
        "        return (ch1, ch2), (cw1, cw2)\n",
        "\n",
        "    def create_model(self, img_shape, num_class):\n",
        "\n",
        "        concat_axis = 3\n",
        "        inputs = layers.Input(shape = img_shape)\n",
        "\n",
        "        conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
        "        conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "        pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "        conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "        conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "        pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "        conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "        conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "        pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "        conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "        conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "        pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "        conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "        conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "        up_conv5 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
        "        ch, cw = self.get_crop_shape(conv4, up_conv5)\n",
        "        crop_conv4 = layers.Cropping2D(cropping=(ch,cw))(conv4)\n",
        "        up6 = layers.concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
        "        conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "        conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "        up_conv6 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
        "        ch, cw = self.get_crop_shape(conv3, up_conv6)\n",
        "        crop_conv3 = layers.Cropping2D(cropping=(ch,cw))(conv3)\n",
        "        up7 = layers.concatenate([up_conv6, crop_conv3], axis=concat_axis) \n",
        "        conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "        conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "        up_conv7 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
        "        ch, cw = self.get_crop_shape(conv2, up_conv7)\n",
        "        crop_conv2 = layers.Cropping2D(cropping=(ch,cw))(conv2)\n",
        "        up8 = layers.concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
        "        conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "        conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "        up_conv8 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
        "        ch, cw = self.get_crop_shape(conv1, up_conv8)\n",
        "        crop_conv1 = layers.Cropping2D(cropping=(ch,cw))(conv1)\n",
        "        up9 = layers.concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
        "        conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "        conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "        ch, cw = self.get_crop_shape(inputs, conv9)\n",
        "        conv9 = layers.ZeroPadding2D(padding=((ch[0], ch[1]), (cw[0], cw[1])))(conv9)\n",
        "        #conv10 = layers.Conv2D(num_class, (1, 1))(conv9)\n",
        "        \n",
        "        \n",
        "        flatten =keras.layers.Flatten()(conv9)\n",
        "        Dense1 = Dense(512, activation='relu')(flatten)\n",
        "        BN =BatchNormalization() (Dense1)\n",
        "        Dense2 = Dense(21, activation='softmax')(BN)\n",
        "\n",
        "        model = models.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "        return model\n",
        "      \n",
        "    def get_unet(self,n_ch,patch_height,patch_width):\n",
        "      \n",
        "        concat_axis = 3\n",
        "\n",
        "        inputs = Input((patch_height, patch_width, n_ch))\n",
        "\n",
        "        conv1 = Conv2D(32, (3, 3), padding=\"same\", name=\"conv1_1\", activation=\"relu\", data_format=\"channels_last\")(inputs)\n",
        "        #conv1 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv1)\n",
        "        pool1 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv1)\n",
        "        \n",
        "        conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(pool1)\n",
        "        #conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv2)\n",
        "        pool2 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv2)\n",
        "\n",
        "        conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(pool2)\n",
        "        #conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv3)\n",
        "        #pool3 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv3)\n",
        "\n",
        "#         conv4 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(pool3)\n",
        "#         #conv4 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv4)\n",
        "#         pool4 = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\")(conv4)\n",
        "\n",
        "#         conv5 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(pool4)\n",
        "#         #conv5 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv5)\n",
        "\n",
        "#         up_conv5 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv5)\n",
        "#         ch, cw = self.get_crop_shape(conv4, up_conv5)\n",
        "#         crop_conv4 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv4)\n",
        "#         up6   = concatenate([up_conv5, crop_conv4], axis=concat_axis)\n",
        "#         conv6 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up6)\n",
        "#         #conv6 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv6)\n",
        "\n",
        "#         up_conv6 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv6)\n",
        "#         ch, cw = self.get_crop_shape(conv3, up_conv6)\n",
        "#         crop_conv3 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv3)\n",
        "#         up7   = concatenate([up_conv6, crop_conv3], axis=concat_axis)\n",
        "#         conv7 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up7)\n",
        "#         #conv7 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv7)\n",
        "\n",
        "#         up_conv7 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv7)\n",
        "#         ch, cw = self.get_crop_shape(conv2, up_conv7)\n",
        "#         crop_conv2 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv2)\n",
        "#         up8   = concatenate([up_conv7, crop_conv2], axis=concat_axis)\n",
        "#         conv8 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up8)\n",
        "#         #conv8 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv8)\n",
        "\n",
        "#         up_conv8 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv8)\n",
        "#         ch, cw = self.get_crop_shape(conv1, up_conv8)\n",
        "#         crop_conv1 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv1)\n",
        "#         up9   = concatenate([up_conv8, crop_conv1], axis=concat_axis)\n",
        "#         conv9 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up9)\n",
        "#         #conv9 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(conv9)\n",
        "\n",
        "#         #ch, cw = get_crop_shape(inputs, conv9)\n",
        "#         #conv9  = ZeroPadding2D(padding=(ch[0],cw[0]), data_format=\"channels_last\")(conv9)\n",
        "#         #conv10 = Conv2D(1, (1, 1), data_format=\"channels_last\", activation=\"sigmoid\")(conv9)\n",
        "\n",
        "\n",
        "        up_conv3 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv3)\n",
        "        ch, cw = self.get_crop_shape(conv2, up_conv3)\n",
        "        crop_conv2 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv2)\n",
        "        up4   = concatenate([up_conv3, crop_conv2], axis=concat_axis) \n",
        "        conv4 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up4)\n",
        "          \n",
        "        up_conv4 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(conv4)\n",
        "        ch, cw = self.get_crop_shape(conv1, up_conv4)\n",
        "        crop_conv1 = Cropping2D(cropping=(ch,cw), data_format=\"channels_last\")(conv1)\n",
        "        up5   = concatenate([up_conv4, crop_conv1], axis=concat_axis) \n",
        "        conv5 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", data_format=\"channels_last\")(up5)\n",
        "        \n",
        "        \n",
        "        flatten =  Flatten()(conv5)\n",
        "        Dense1 = Dense(128, activation='relu')(flatten)\n",
        "        BN =BatchNormalization() (Dense1)\n",
        "        Dense2 = Dense(21, activation='sigmoid')(BN)\n",
        "\n",
        "        model = Model(input=inputs, output=Dense2)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "hello = UNet()\n",
        "\n",
        "\n",
        "model = hello.get_unet(3, 256, 256)\n",
        "#model = hello.create_model(input_shape,21)\n",
        "\n",
        "\n",
        "# model = tf.keras.models.Sequential()\n",
        "# model.add(tf.keras.layers.Convolution2D(32, (3, 3),activation='relu',input_shape=input_shape))\n",
        "# #model.add(tf.keras.layers.Conv2D(32, (3, 3),activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(64, (3, 3),activation='relu'))\n",
        "# #model.add(tf.keras.layers.Conv2D(64, (3, 3),activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(128, (3, 3),activation='relu'))\n",
        "# #model.add(tf.keras.layers.Conv2D(128, (3, 3),activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(256, (3, 3),activation='relu'))\n",
        "# #model.add(tf.keras.layers.Conv2D(256, (3, 3),activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# #model.add(tf.keras.layers.Conv2D(512, (3, 3),activation='relu'))\n",
        "# model.add(tf.keras.layers.Conv2D(512, (3, 3),activation='relu'))\n",
        "\n",
        "# model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "# model.add(tf.keras.layers.Conv2D(256, (3, 3),activation='relu'))\n",
        "\n",
        "# model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "# model.add(tf.keras.layers.Conv2D(128, (3, 3),activation='relu'))\n",
        "\n",
        "# model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "# model.add(tf.keras.layers.Conv2D(64, (3, 3),activation='relu'))\n",
        "\n",
        "# model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/\n",
            "['parkinglot', 'storagetanks', 'runway', 'sparseresidential', 'river', 'overpass', 'tenniscourt', 'mobilehomepark', 'beach', 'buildings', 'freeway', 'golfcourse', 'harbor', 'chaparral', 'intersection', 'denseresidential', 'mediumresidential', 'forest', 'baseballdiamond', 'airplane', 'agricultural']\n",
            "(1946, 3, 256, 256)\n",
            "(1946, 1)\n",
            "(105, 3, 256, 256)\n",
            "(105, 1)\n",
            "build UNet ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:192: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "H-yAqNSLxLi5",
        "colab_type": "code",
        "outputId": "1ba8a3e9-31c1-4241-96da-af6cf72bcc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "# TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "# tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "# tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "#     model,\n",
        "#     strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "#         tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  print(devices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.38.33.42:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 11577002308664079222), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5635832503111318103), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9665912832239048173), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10040119896148797786), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5133137750359844171), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13659516597524339813), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12284649909342530000), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1841613888373672532), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16309168400290056244), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17891843764298591940), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 10636815779171783693)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sYV_cADN3_FL",
        "colab_type": "code",
        "outputId": "f53ff54a-baa5-4191-cf89-b36609bbf4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1153
        }
      },
      "cell_type": "code",
      "source": [
        "# TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "# tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "# tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "#     model,\n",
        "#     strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "#         tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "print(tpu_address)\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "# tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "#     model,\n",
        "#     strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "#         tf.contrib.cluster_resolver.TPUClusterResolver(tpu_address)))    \n",
        "# # tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "# #     model,strategy\n",
        "# #    )\n",
        "    \n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "        model,\n",
        "        strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "            tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "        )\n",
        "    )\n",
        "tpu_model.compile(\n",
        "        optimizer=tf.train.AdamOptimizer(0.001),\n",
        "        loss=tf.keras.losses.categorical_crossentropy,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "\n",
        "# tpu_model.fit(x_train, y_train, batch_size=64, nb_epoch=100, verbose=1, validation_data=(x_test, y_test))\n",
        "# loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# tpu_model.summary()\n",
        "\n",
        "# print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grpc://10.38.33.42:8470\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.38.33.42:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11577002308664079222)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5635832503111318103)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9665912832239048173)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10040119896148797786)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5133137750359844171)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13659516597524339813)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12284649909342530000)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1841613888373672532)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 16309168400290056244)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17891843764298591940)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 10636815779171783693)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5ee30a7d106c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         strategy=tf.contrib.tpu.TPUDistributionStrategy(\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/framework/experimental.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m'any time, and without warning.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         decorator_utils.get_qualified_name(func), func.__module__)\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   new_func.__doc__ = _add_experimental_function_notice_to_docstring(\n\u001b[1;32m     66\u001b[0m       func.__doc__)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36mtpu_model\u001b[0;34m(model, strategy)\u001b[0m\n\u001b[1;32m   2226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m   \u001b[0;31m# Force initialization of the CPU model in the TPU session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2228\u001b[0;31m   \u001b[0mcpu_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m     cpu_model.compile(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_clone_sequential_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_clone_functional_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     raise ValueError('Expected `model` argument '\n\u001b[0;32m---> 69\u001b[0;31m                      'to be a `Model` instance, got ', model)\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     raise ValueError('Expected `model` argument '\n",
            "\u001b[0;31mValueError\u001b[0m: ('Expected `model` argument to be a `Model` instance, got ', <keras.engine.training.Model object at 0x7fa66a6ab4a8>)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tOx0IKsBRhh7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.compile(\n",
        "#         optimizer=tf.train.AdamOptimizer(0.001),\n",
        "#         loss=tf.keras.losses.categorical_crossentropy,\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
        "                  optimizer=tf.train.AdamOptimizer(0.001),\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lvQUzRAnQGTp",
        "colab_type": "code",
        "outputId": "0ee13c63-2c5f-462d-a670-91b8100a118a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1261
        }
      },
      "cell_type": "code",
      "source": [
        "# model.fit(x_train, y_train, batch_size=50, nb_epoch=3, verbose=50, validation_data=(x_test, y_test))\n",
        "# print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
        "\n",
        "# loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "model.fit(x = x_train, y= y_train, validation_data=(x_test, y_test),\n",
        "          batch_size=16, verbose=1, epochs=10, shuffle=True)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "# model.fit(x_train, y_train, batch_size=64, nb_epoch=10, verbose=1, validation_data=(x_test, y_test))\n",
        "# loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 1946 samples, validate on 105 samples\n",
            "Epoch 1/10\n",
            "1946/1946 [==============================] - 92s 47ms/step - loss: 0.4710 - acc: 0.8578 - val_loss: 0.2362 - val_acc: 0.9537\n",
            "Epoch 2/10\n",
            "1946/1946 [==============================] - 77s 40ms/step - loss: 0.1646 - acc: 0.9538 - val_loss: 0.2174 - val_acc: 0.9274\n",
            "Epoch 3/10\n",
            "1946/1946 [==============================] - 77s 40ms/step - loss: 0.1268 - acc: 0.9573 - val_loss: 0.2515 - val_acc: 0.9528\n",
            "Epoch 4/10\n",
            "1946/1946 [==============================] - 77s 40ms/step - loss: 0.0874 - acc: 0.9679 - val_loss: 0.2958 - val_acc: 0.9220\n",
            "Epoch 5/10\n",
            "1946/1946 [==============================] - 77s 39ms/step - loss: 0.0568 - acc: 0.9824 - val_loss: 0.8583 - val_acc: 0.7098\n",
            "Epoch 6/10\n",
            "1946/1946 [==============================] - 77s 39ms/step - loss: 0.0331 - acc: 0.9935 - val_loss: 0.6147 - val_acc: 0.9546\n",
            "Epoch 7/10\n",
            "1946/1946 [==============================] - 78s 40ms/step - loss: 0.0198 - acc: 0.9978 - val_loss: 0.3012 - val_acc: 0.9084\n",
            "Epoch 8/10\n",
            "1946/1946 [==============================] - 78s 40ms/step - loss: 0.0127 - acc: 0.9992 - val_loss: 0.4661 - val_acc: 0.8803\n",
            "Epoch 9/10\n",
            "1946/1946 [==============================] - 78s 40ms/step - loss: 0.0083 - acc: 0.9997 - val_loss: 0.2127 - val_acc: 0.9556\n",
            "Epoch 10/10\n",
            "1946/1946 [==============================] - 78s 40ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9533\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_1 (Conv2D)                (None, 256, 256, 32) 896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           conv1_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d_1 (Cropping2D)       (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_1[0][0]            \n",
            "                                                                 cropping2d_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 64) 110656      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d_2 (Cropping2D)       (None, 256, 256, 32) 0           conv1_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256, 256, 96) 0           up_sampling2d_2[0][0]            \n",
            "                                                                 cropping2d_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 256, 256, 32) 27680       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2097152)      0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          268435584   flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 21)           2709        batch_normalization_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 268,670,389\n",
            "Trainable params: 268,670,133\n",
            "Non-trainable params: 256\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "Testing loss: 0.20566210058473405, acc: 0.9532879681814285\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GZBxbJ9zYCJp",
        "colab_type": "code",
        "outputId": "68357d7a-fb6b-47c8-a421-7615b4658954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-99704cdb8844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# serialize model to JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GGESuwp_wB1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows = 256\n",
        "img_cols = 256\n",
        "num_class = 21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KcRvN9nOM7C2",
        "colab_type": "code",
        "outputId": "c707437a-cec8-4458-ee5e-d44e5be0d62b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "x_demo,y_demo = test_img('content/')\n",
        "print(\"x-demo\")\n",
        "print(x_demo)\n",
        "  \n",
        "x_demo = x_demo.reshape(x_demo.shape[0], img_rows, img_cols, 3)\n",
        "\n",
        "x_demo = x_demo.astype('float32')\n",
        "x_demo /= 255\n",
        "y_demo = keras.utils.to_categorical(y_demo, 21)\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mae', 'acc'])\n",
        "print(y_demo)\n",
        "y_prob = loaded_model.predict(x_demo)\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "print(y_classes)\n",
        "score = loaded_model.evaluate(x_demo, y_demo, verbose=1)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "256\n",
            "x-demo\n",
            "[[[[ 2 27 68 ... 44 48 45]\n",
            "   [ 6 44 65 ... 72 52 57]\n",
            "   [ 6 25 27 ... 82 71 66]\n",
            "   ...\n",
            "   [91 87 81 ... 12 16 17]\n",
            "   [71 58 60 ... 14 26 21]\n",
            "   [35 11 29 ... 45 57 36]]\n",
            "\n",
            "  [[ 2 29 69 ... 50 52 46]\n",
            "   [ 7 45 66 ... 78 57 58]\n",
            "   [11 28 28 ... 87 76 69]\n",
            "   ...\n",
            "   [92 88 80 ... 13 18 19]\n",
            "   [74 61 63 ... 17 30 23]\n",
            "   [42 19 37 ... 48 61 42]]\n",
            "\n",
            "  [[ 3 31 72 ... 45 50 45]\n",
            "   [ 6 45 69 ... 77 57 60]\n",
            "   [ 6 27 30 ... 93 79 72]\n",
            "   ...\n",
            "   [90 85 77 ...  8 15 19]\n",
            "   [73 60 62 ...  9 23 19]\n",
            "   [44 19 37 ... 37 49 31]]]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "[17]\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "mean_absolute_error: 4.80%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}